{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-14T08:59:24.409567Z",
     "start_time": "2025-09-14T08:59:24.406759Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### # Image Augmentation\n",
    "#### - Add more variations to training images\n",
    "#### - Techniques: flip, rotate, crop, noise\n",
    "#### - Libraries: OpenCV, NumPy"
   ],
   "id": "f3648414056514c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:59:24.455686Z",
     "start_time": "2025-09-14T08:59:24.453550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dir = \"./data/prepared-2\"\n",
    "output_dir = \"./data/prepared-train\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "id": "6b57a25d303f1bc5",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:59:24.504009Z",
     "start_time": "2025-09-14T08:59:24.501122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# count images\n",
    "image_paths = glob(os.path.join(input_dir, \"*.jpg\"))\n",
    "print(f\"Total images: {len(image_paths)}\")"
   ],
   "id": "75c8516155c853b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 75\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:59:24.885391Z",
     "start_time": "2025-09-14T08:59:24.550819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def augment_image(img):\n",
    "    augmented = []\n",
    "\n",
    "    # Flip\n",
    "    augmented.append((\"flip_h\", cv2.flip(img, 1)))   # horizontal\n",
    "    augmented.append((\"flip_v\", cv2.flip(img, 0)))   # vertical\n",
    "\n",
    "    # Rotate\n",
    "    (h, w) = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), 15, 1.0)\n",
    "    augmented.append((\"rot15\", cv2.warpAffine(img, M, (w, h))))\n",
    "\n",
    "    # Crop (random crop)\n",
    "    cropped = img[5:h-5, 5:w-5]\n",
    "    cropped = cv2.resize(cropped, (w, h))\n",
    "    augmented.append((\"crop\", cropped))\n",
    "\n",
    "    # Noise\n",
    "    noise = np.random.normal(0, 75, img.shape).astype(np.uint8)\n",
    "    noisy = cv2.add(img, noise)\n",
    "    augmented.append((\"noise\", noisy))\n",
    "\n",
    "    return augmented\n",
    "\n",
    "# -----------------------------\n",
    "# Process Images\n",
    "# -----------------------------\n",
    "image_paths = glob(os.path.join(input_dir, \"*.jpg\"))\n",
    "\n",
    "for path in image_paths:\n",
    "    label = os.path.basename(os.path.dirname(path))\n",
    "    fname = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "    # เตรียมโฟลเดอร์ class\n",
    "    out_class_dir = output_dir\n",
    "    os.makedirs(out_class_dir, exist_ok=True)\n",
    "\n",
    "    # โหลดภาพ\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    # save original\n",
    "    cv2.imwrite(os.path.join(out_class_dir, f\"{fname}_orig.jpg\"), img)\n",
    "\n",
    "    # save augmentations\n",
    "    for aug_name, aug_img in augment_image(img):\n",
    "        out_path = os.path.join(out_class_dir, f\"{fname}_{aug_name}.jpg\")\n",
    "        cv2.imwrite(out_path, aug_img)\n",
    "\n",
    "print(\"✅ เสร็จสิ้น: Augmented images saved to\", output_dir)"
   ],
   "id": "357ffbb8762e8a64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ เสร็จสิ้น: Augmented images saved to ./data/prepared-train\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### # Prepare Data for Training",
   "id": "e2ca8d1722009d57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:59:24.897413Z",
     "start_time": "2025-09-14T08:59:24.893268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dir = \"./data/prepared-train\"\n",
    "volume_dir = \"data/volumes\"\n",
    "\n",
    "image_paths = glob(os.path.join(input_dir, \"*.jpg\"))\n",
    "print(f\"Total images: {len(image_paths)}\")"
   ],
   "id": "889638fbbf65f90d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 450\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:59:24.946113Z",
     "start_time": "2025-09-14T08:59:24.943515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge"
   ],
   "id": "bec28c845e953fe9",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5f8e22020ef7ce81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T08:59:24.993958Z",
     "start_time": "2025-09-14T08:59:24.990924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# images, labels = [], []\n",
    "#\n",
    "# for img_path in glob(os.path.join(input_dir, \"*.jpg\")):\n",
    "#     prefix = os.path.splitext(os.path.basename(img_path))[0].split(\"_\")[0]  # เช่น i001\n",
    "#\n",
    "#     vol_path = os.path.join(volume_dir, f\"{prefix}_mangosteen_grid.txt\")\n",
    "#     if not os.path.exists(vol_path):\n",
    "#         continue\n",
    "#\n",
    "#     # โหลดรูป\n",
    "#     img = cv2.imread(img_path)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.resize(img, (224, 224))\n",
    "#     img = img / 255.0  # normalize\n",
    "#     images.append(img)\n",
    "#\n",
    "#     # โหลด volume\n",
    "#     with open(vol_path) as f:\n",
    "#         vol = float(f.read().strip())\n",
    "#     labels.append(vol)\n",
    "#\n",
    "# X = np.array(images, dtype=\"float32\")\n",
    "# y = np.array(labels, dtype=\"float32\")\n",
    "#\n",
    "# print(\"Dataset:\", X.shape, y.shape)\n",
    "#\n",
    "# # --------------------------\n",
    "# # 2. Train-Test Split\n",
    "# # --------------------------\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "#\n",
    "# # --------------------------\n",
    "# # 3. Build CNN Regression Model\n",
    "# # --------------------------\n",
    "# base_model = tf.keras.applications.MobileNetV2(\n",
    "#     input_shape=(224,224,3), include_top=False, weights=\"imagenet\"\n",
    "# )\n",
    "# base_model.trainable = False  # freeze transfer learning\n",
    "#\n",
    "# model = tf.keras.Sequential([\n",
    "#     base_model,\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(1, activation=\"linear\")   # regression output\n",
    "# ])\n",
    "#\n",
    "# model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "# model.summary()\n",
    "#\n",
    "# # --------------------------\n",
    "# # 4. Train\n",
    "# # --------------------------\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_split=0.2,\n",
    "#     epochs=20,\n",
    "#     batch_size=8,\n",
    "#     verbose=1\n",
    "# )\n",
    "#\n",
    "# # --------------------------\n",
    "# # 5. Evaluate\n",
    "# # --------------------------\n",
    "# y_pred = model.predict(X_test).flatten()\n",
    "#\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2  = r2_score(y_test, y_pred)\n",
    "#\n",
    "# print(\"\\n=== Evaluation ===\")\n",
    "# print(\"Mean Absolute Error (MAE):\", mae)\n",
    "# print(\"R² Score:\", r2)"
   ],
   "id": "42eb8407589f0e21",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### # Traditional ML Models\n",
    "#### - Random Forest, Gradient Boosting, Ridge Regression"
   ],
   "id": "ba8b462366491173"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-14T08:59:25.039593Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (450, 12288) (450,)\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "X, y = [], []\n",
    "\n",
    "for img_path in glob(os.path.join(input_dir, \"*.jpg\")):\n",
    "    prefix = os.path.splitext(os.path.basename(img_path))[0].split(\"_\")[0]  # เช่น i001\n",
    "    vol_path = os.path.join(volume_dir, f\"{prefix}_mangosteen_grid.txt\")\n",
    "\n",
    "    if not os.path.exists(vol_path):\n",
    "        continue\n",
    "\n",
    "    # โหลดรูป -> resize และ flatten เป็น vector\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (64, 64))  # ลดขนาดเพื่อให้ feature ไม่เยอะเกินไป\n",
    "    feat = img.flatten() / 255.0\n",
    "\n",
    "    # โหลด label\n",
    "    with open(vol_path) as f:\n",
    "        vol = float(f.read().strip())\n",
    "\n",
    "    X.append(feat)\n",
    "    y.append(vol)\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "print(\"Dataset:\", X.shape, y.shape)\n",
    "\n",
    "# --------------------------\n",
    "# 2. Train-Test Split\n",
    "# --------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 3. Define models\n",
    "# --------------------------\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0, random_state=42)\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# 4. Train & Evaluate\n",
    "# --------------------------\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R² : {r2:.4f}\")"
   ],
   "id": "d2607bd72f038dd4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
