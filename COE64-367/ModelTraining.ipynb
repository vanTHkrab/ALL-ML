{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T10:30:34.668713Z",
     "start_time": "2025-08-31T10:30:31.500988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ],
   "id": "96a81d92e1415115",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 17:30:31.992341: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T10:30:34.676625Z",
     "start_time": "2025-08-31T10:30:34.673944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- 1. CONFIGURATION AND SETUP ---\n",
    "# Update these paths to match your local computer's file structure\n",
    "DATA_DIR = \"./data/processed/images\"\n",
    "VOLUME_FILES_DIR = \"./data/processed/volumes\"\n",
    "MODEL_SAVE_PATH = \"./models/mangosteen_volume_model_all_suggessions_2.h5\" # Saves in the current working directory"
   ],
   "id": "fa5361a887d2106f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T10:30:34.720227Z",
     "start_time": "2025-08-31T10:30:34.718004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model parameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_EPOCHS = 30 # Reduced for initial head training\n",
    "FINE_TUNE_EPOCHS = 70 # Increased for fine-tuning the backbone\n",
    "LEARNING_RATE_INITIAL = 1e-3\n",
    "LEARNING_RATE_FINE_TUNE = 1e-5"
   ],
   "id": "3c8b1cdd9bf703d1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T10:31:17.466422Z",
     "start_time": "2025-08-31T10:31:17.218070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 2. DATA LOADING AND PREPARATION ---\n",
    "\n",
    "def load_data_from_folders(data_dir, volume_dir):\n",
    "    \"\"\"\n",
    "    Loads images and their corresponding volume values.\n",
    "    It expects images and text files to share a base filename.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the directory containing images.\n",
    "        volume_dir (str): Path to the directory containing volume text files.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of lists containing image paths and their corresponding volumes.\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    volumes = []\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"❌ Image data directory not found: {data_dir}\")\n",
    "        return [], []\n",
    "    if not os.path.exists(volume_dir):\n",
    "        print(f\"❌ Volume data directory not found: {volume_dir}\")\n",
    "        return [], []\n",
    "\n",
    "    for filename in sorted(os.listdir(data_dir)):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # The base filename is everything before the file extension\n",
    "            base_filename = filename.split('.', 1)[0]\n",
    "\n",
    "            volume_filename = f\"{base_filename}.txt\"\n",
    "\n",
    "            volume_filepath = None\n",
    "            if os.path.exists(os.path.join(volume_dir, volume_filename)):\n",
    "                volume_filepath = os.path.join(volume_dir, volume_filename)\n",
    "\n",
    "            if volume_filepath:\n",
    "                try:\n",
    "                    # Read the single volume value from the text file\n",
    "                    with open(volume_filepath, 'r') as f:\n",
    "                        volume_value = float(f.read().strip())\n",
    "                        image_paths.append(os.path.join(data_dir, filename))\n",
    "                        volumes.append(volume_value)\n",
    "                except (ValueError, FileNotFoundError) as e:\n",
    "                    print(f\"⚠️ Skipping file {filename}: Could not read volume file. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Skipping file {filename}: No matching volume file found.\")\n",
    "\n",
    "    return image_paths, volumes\n",
    "\n",
    "print(\"Loading data...\")\n",
    "image_paths, volumes = load_data_from_folders(DATA_DIR, VOLUME_FILES_DIR)\n",
    "\n",
    "if not image_paths:\n",
    "    print(\"❌ No matching image and volume data found. Please check your paths and file names.\")\n",
    "    exit()\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_paths, val_paths, train_volumes, val_volumes = train_test_split(\n",
    "    image_paths, volumes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total samples found: {len(image_paths)}\")\n",
    "print(f\"Training samples: {len(train_paths)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")\n"
   ],
   "id": "4b5669e066511f9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DATA_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 51\u001B[39m\n\u001B[32m     48\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m image_paths, volumes\n\u001B[32m     50\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mLoading data...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m image_paths, volumes = load_data_from_folders(\u001B[43mDATA_DIR\u001B[49m, VOLUME_FILES_DIR)\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m image_paths:\n\u001B[32m     54\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m❌ No matching image and volume data found. Please check your paths and file names.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'DATA_DIR' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Data Augmentation function for brightness and contrast ---\n",
    "def augment_image(image):\n",
    "    # Convert image to float32 for augmentation\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "\n",
    "    # Randomly adjust brightness by a factor between -0.2 and 0.2\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "\n",
    "    # Randomly adjust contrast by a factor between 0.8 and 1.2\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "\n",
    "    # Clip the augmented image to the valid range [0, 255]\n",
    "    return tf.clip_by_value(image, 0.0, 255.0)\n",
    "\n",
    "\n",
    "# Data Generators\n",
    "# We use a custom generator to load images and their corresponding volumes\n",
    "def data_generator(image_paths, volumes, batch_size, is_training=True):\n",
    "    num_samples = len(image_paths)\n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "\n",
    "            batch_images = []\n",
    "            batch_volumes = []\n",
    "\n",
    "            for i in batch_indices:\n",
    "                img = cv2.imread(image_paths[i])\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Ensure correct color format\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) # Resize to model input size\n",
    "                batch_images.append(img)\n",
    "                batch_volumes.append(volumes[i])\n",
    "\n",
    "            # Apply augmentation only to the training set\n",
    "            if is_training:\n",
    "                batch_images = augment_image(np.array(batch_images, dtype=\"float32\"))\n",
    "            else:\n",
    "                batch_images = np.array(batch_images, dtype=\"float32\")\n",
    "\n",
    "            batch_images = batch_images / 255.0 # Normalize pixel values\n",
    "            batch_volumes = np.array(batch_volumes, dtype=\"float32\")\n",
    "\n",
    "            yield batch_images, batch_volumes\n",
    "\n",
    "# Create generators for training and validation\n",
    "train_generator = data_generator(train_paths, train_volumes, BATCH_SIZE, is_training=True)\n",
    "val_generator = data_generator(val_paths, val_volumes, BATCH_SIZE, is_training=False)\n",
    "\n",
    "# --- 3. MODEL ARCHITECTURE ---\n",
    "print(\"\\nBuilding model...\")\n",
    "# Load the Xception model with pre-trained ImageNet weights, excluding the top layers\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Add a new regression head on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x) # Add L2 regularization\n",
    "x = Dropout(0.3)(x) # Add a Dropout layer\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x) # Add L2 regularization\n",
    "predictions = Dense(1, activation='linear')(x) # Use 'linear' activation for regression\n",
    "\n",
    "# Create the full model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# First stage: Freeze the convolutional layers and train only the head\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE_INITIAL), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "print(\"Training the regression head...\")\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_paths) // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_paths) // BATCH_SIZE,\n",
    "    epochs=INITIAL_EPOCHS,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "               ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)]\n",
    ")\n",
    "\n",
    "\n",
    "# Second stage: Fine-tuning\n",
    "print(\"\\nFine-tuning the model...\")\n",
    "\n",
    "# Unfreeze the last few convolutional blocks of the base model\n",
    "for layer in base_model.layers:\n",
    "    # A more selective approach to unfreeze only the last few blocks\n",
    "    if \"block13\" in layer.name or \"block14\" in layer.name: # These are the last two blocks in Xception\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Re-compile the model with a lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE_FINE_TUNE),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "# Continue training with the fine-tuned model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_paths) // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_paths) // BATCH_SIZE,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "               ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)]\n",
    ")\n",
    "\n",
    "# --- 5. SAVING THE MODEL ---\n",
    "print(f\"\\nTraining complete. Saving model to {MODEL_SAVE_PATH}\")\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(\"✅ Model saved successfully.\")\n",
    "\n",
    "# You can now unfreeze some layers for fine-tuning if needed\n",
    "# or use this model for inference to estimate mangosteen volumes.\n"
   ],
   "id": "e2a7ac8005eee48e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
